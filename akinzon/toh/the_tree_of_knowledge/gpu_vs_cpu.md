# GPU vs [The Processor|CPU](the_processor|cpu)

Up: [The GPU](the_gpu)
Brother(s):
TARGET DECK
Leaves of the Tree of Ohara::Branch I::Semester I::1203 CompSys::Computer Systems

|  | CPU | GPU |
| ---- | ---- | ---- |
| Clock speed | ~4GHz | ~2GHz |
| Core count | $\leq$ 128 | $\leq$ 16,384$^*$ |
| Power | 50W-350W | 100W-450W |
| High-end Transistor Count | 78B | 76B |
| High-end FP32 "Performance" | ~10 TFLOPS | ~100 TFLOPS |
$^*$ GPUs may have many more cores, but [CUDA cores](cuda_cores) aren't full processor cores

FP32 - 32-bit floating point arithmetic

Why might someone prefer to use their GPU for floating point maths over their CPU? #flashcard 
[The GPU](the_gpu) is a [Single Input, Multiple Data|SIMD](single_input,_multiple_data|simd) powerhouse and excels at performing the same operation on multiple pieces of data simultaneously.
<!--ID: 1705597926943-->



































#### Why:
#### How:









